 <!DOCTYPE html>
<html>
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="google-site-verification" content="XilvwLQhsKzjrU7KUsndrYKzKy__exj0GnhpBgLZFHY" />
    <meta charset="UTF-8">
    <title>Philippe Laban - Researcher</title>
    <link rel="stylesheet" href="main.css">
    <link rel="stylesheet" href="garden.css">
    <style id="flower_css"></style>
</head>
<body>
    <div id="column">
        <div id="first_block">
            <div id="name">Philippe Laban</div>
            <div id="right_block">
                <img src="phil20.jpeg" id="phil_image" />
                <a href="mailto:plaban@microsoft.com">plaban@microsoft.com</a><br />
                <a href="https://www.linkedin.com/in/philippe-laban-b5a59b66/" target="_blank" style="color: #005795;">LinkedIn</a><br />
                <a href="https://x.com/PhilippeLaban" target="_blank" style="color: #005795;">X/Twitter</a><br />
                <a href="https://scholar.google.com/citations?user=fR5t200AAAAJ&hl=en&oi=ao" target="_blank" style="color: #005795;">Google Scholar</a>
            </div>
            <div id="intro_para">
                Hi! I'm a Research Scientist at <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a>, based in New York. I completed my Ph.D. in CS in 2021, advised by 
                <a href="http://people.ischool.berkeley.edu/~hearst/">Marti Hearst</a> and <a href="https://people.eecs.berkeley.edu/~jfc/">John Canny</a> at UC Berkeley.<br /><br />
    
                I work at the intersection of NLP (~70%) and HCI (~30%). I am passionate about studying and building the future of <span style="color: #a8372f;">reading</span> and <span style="color: #379644;">writing</span> interfaces as I believe that NLP technology will revolutionize how we <span style="color: #a8372f;">consume</span> (read) and <span style="color: #379644;">create</span> (write) information. How do we get there?<br /><br />

                Specific tasks I'm passionate about include <span style="color: #b3890d;">summarization</span>, <span style="color: #379644;">simplification</span> (which you can think of as "reading tools" if you choose to), and <span style="color: #6d3cdf;">LLM evaluation/benchmarking</span>.<br /><br />
    
                See my research garden below for a visual organization of some of my work, or my <a href="https://scholar.google.com/citations?user=fR5t200AAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a> for a full list of publications.
            </div>
        </div>
    </div>

    <!-- Research Garden -->
    <svg id="flower_template" xmlns="http://www.w3.org/2000/svg" viewBox="-10 -10 20 20">
        <ellipse rx="10" ry="20" transform="rotate(0)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(45)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(90)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(135)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(180)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(225)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(270)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(315)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <circle r="6" fill="white"/>
    </svg>
    <div id="garden_title">Philippe's Research Garden</div>
    <div id="garden_container">
        <svg id="garden" preserveAspectRatio="xMinYMin meet"></svg>
     </div>
     <div id="coauthor_hall_of_fame">
        <div id="coauthor_title">Recurrent Coauthors ("Hall of Friends")</div>
        <div id="coauthor_list"></div>
    </div>
    <div id="paper_modal">
        <!-- a close icon at the top right -->
        <div id="paper_modal_close" onclick="$('#paper_modal').fadeOut(200);">X</div>
        <div id="paper_modal_title"></div>
        <div id="paper_modal_venue"></div>
        <div id="paper_modal_content"></div>
        <div id="paper_modal_links"></div>
    </div>

    <div class="section">
        <div class="section_title">Want your own Research Garden visualization?</div>
        <p>
            All you need is: (1) <a href="https://tingofurro.github.io/garden.css" target="_blank">garden.css</a>, (2) <a href="https://tingofurro.github.io/garden.js" target="_blank">garden.js</a>, and (3) <a href="https://github.com/tingofurro/tingofurro.github.io/blob/main/simple_garden.html" target="_blank">an HTML file</a>. In the HTML file, there's a javascript variable <code>var papers = [...];</code> that you can modify to include your own papers. If you end up using it, feel free to send me a link, so I can check it out!
        </p>
    </div>

    <div class="section" id="reach_out">
        <div class="section_title">Reach out!</div>

        <p>
            Thanks for visiting my website! Here are some reasons to reach out to me:
            <ul>
                <li><b>You're a researcher</b>, and you have a question about some of my work, or want to brainstorm, pitch a research project, debug an idea, etc.</li>
                <li><b>You're a journalist</b>, and want an technical opinion on a topic I have expertise in. (See some articles I've been interviewed for <a href="https://www.nytimes.com/2023/11/06/technology/chatbots-hallucination-rates.html">NYTimes</a>, <a href="https://www.science.org/content/article/is-your-ai-hallucinating-new-approach-can-tell-when-chatbots-make-things-up">Science</a>, <a href="https://www.lemonde.fr/pixels/article/2024/06/17/faut-il-s-inquieter-des-hallucinations-des-ia-comme-chatgpt-ou-gemini_6240971_4408996.html">Le Monde</a>, <a href="https://podcasts.apple.com/ca/podcast/like-your-new-best-friend-an-ai-chatbot/id1639175294?i=1000575694297">Podcast</a>)</li>
                <li><b>You work at a startup</b>, and want technical expertise, either informally or as a board member/consultant. I've advised a few startups with products related to news reading, summarization, and factuality.</li>
                <li><b>You work on NLP/HCI in NYC</b>, and want to grab a coffee to meet likeminded folks in the city.</li>
            </ul>

            This list is likely not exhaustive. When in doubt, reach out by email!
        </p>
    </div>


    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>

    <script src="garden.js?v=2"></script>
    <script>
        var papers = [
        // {"id": "shuffle_test", "title": "Coherence: Shuffle Test", "venue": "ACL2021", "url": "https://arxiv.org/abs/2107.03448", "root_node": 1, "root_name": "Interacting\n2023-now", "root_color": "#D1BDFF", "coauthors": ["Luke Dai", "Lucas Bandarkar", "Marti A. Hearst"], "full_title": "Can Transformer Models Measure Coherence In Text? Re-Thinking the Shuffle Test", "summary": "Basic experiment that shows that a commonly used test to measure coherence in text (the Shuffle test) is saturated and ineffective, and encouraging the community to use more complex forms of the test (k-block Shuffle test).", "additional_links": {"code": "https://github.com/tingofurro/shuffle_test", "video": "https://aclanthology.org/2021.acl-short.134.mp4"}},
        // {"id": "quiz_design", "title": "QG: Quiz Design", "venue": "NAACL2022", "url": "https://arxiv.org/abs/2205.01730", "parent": "shuffle_test", "coauthors": ["Chien-Sheng Wu", "Lidiya Murakhovs'ka", "Wenhao Liu", "Caiming Xiong"], "full_title": "Quiz Design Task: Helping Teachers Create Quizzes with Automated Question Generation", "summary": "How do we evaluate question generation models (LLMs that generate questions). We recruited teachers/educators with experience designing exams, and asked them to use the QG models, finding that they tend to have strong agreement on questions they would select for an exam.", "additional_links": {"code": "https://github.com/salesforce/QGen"}},
        // {"id": "nnd", "title": "Near-Negative Distinction", "venue": "EMNLP2022", "url": "https://arxiv.org/abs/2205.06871", "parent": "quiz_design", "coauthors": ["Chien-Sheng Wu", "Caiming Xiong"], "full_title": "Near-Negative Distinction: Giving a Second Life to Human Evaluation Datasets", "summary": "A proposed method to improve evaluation methodology of generative models in cases where multiple references/candidates have been annotated.", "additional_links": {"code": "https://github.com/salesforce/nnd_evaluation"}},
        {"id": "flipflop", "title": "FlipFlop Experiment", "venue": "arXiv", "url": "https://arxiv.org/abs/2311.08596", "root_node": 1, "root_name": "Interacting\n2023-now", "root_color": "#D1BDFF", "coauthors": ["Lidiya Murakhovs'ka", "Caiming Xiong", "Chien-Sheng Wu"], "full_title": "Are You Sure? Challenging LLMs Leads to Performance Drops in The FlipFlop Experiment", "summary": "What happens when you give an LLM a classification task, it gets it right, and you ask it `Are you sure?`. Universally, LLMs tend to flip their answer: favoring to a superficial agreement with the user over being accurate. We connect the FlipFlop effect with the connect of sycophancy in LLMs, and show that finetuning is not a panacea to cure the issue, although it helps a bit."},
        {"id": "lost_in_conv", "title": "Lost in Conversation", "venue": "arXiv", "url": "https://arxiv.org/abs/2505.06120", "parent": "flipflop", "coauthors": ["Hiroaki Hayashi", "Yingbo Zhou", "Jennifer Neville"], "full_title": "LLMs Get Lost In Multi-Turn Conversation", "summary": "A large-scale simulation experiment with 15 LLMs. We show that on the exact same set of tasks, model performance degrades (39%!) in multi-turn underspecified conversation, compared to single-turn, fully-specified conversations. We find that this is because when models take a wrong turn, they get lost and do not recover (reliability issue rather than aptitude).", "additional_links": {"code": "https://github.com/microsoft/lost_in_conversation", "data": "https://huggingface.co/datasets/microsoft/lost_in_conversation"}},

        {"id": "keepitsimple", "title": "Keep It Simple", "venue": "ACL2021", "url": "https://arxiv.org/abs/2107.03444", "root_node": 1, "root_name": "Writing/Editing\n2020-now", "root_color": "#B3F5BC", "coauthors": ["Tobias Schnabel", "Paul Bennett", "Marti A. Hearst"], "full_title": "Keep it Simple: Unsupervised Simplification of Multi-Paragraph Text", "summary": "First baby steps in the field of simplification (a sister task to summarization). We approached it in an entirely unsupervised way (a la Summary Loop), by crafting rewards for fluency, relevance, and simplicity, and optimizing through RL. Neat Finding: an algorithmic improvement to the popular SCST algorithm (k-SCST) which yielded much more stable training, and better models. Also: a focus on paragraph-level (rather than sentence-level) simplification, which was not so common at the time!", "additional_links": {"code": "https://github.com/tingofurro/keep_it_simple", "video": "https://aclanthology.org/2021.acl-long.498.mp4", "model": "https://huggingface.co/philippelaban/keep_it_simple"}},
        {"id": "swipe", "title": "SWiPE", "venue": "ACL2023", "url": "https://arxiv.org/abs/2305.19204", "parent": "keepitsimple", "coauthors": ["Jesse Vig", "Wojciech Kryscinski", "Caiming Xiong", "Chien-Sheng Wu"], "full_title": "SWiPE: A Dataset for Document-Level Simplification of Wikipedia Pages", "summary": "Improved the extraction process of simplification document pairs from Simple Wikipedia, showing that Swiki is a great resource to study the simplification process. Prior work had mostly disregarded SWiki in favor of less publicly available datasets such as Newsela.", "additional_links": {"code": "https://github.com/salesforce/simplification"}},
        {"id": "art_or_artifice", "title": "Art or Artifice", "venue": "CHI2024", "url": "https://arxiv.org/abs/2309.14556", "parent": "swipe", "coauthors": ["Tuhin Chakrabarty", "Chien-Sheng Wu"], "full_title": "Art or Artifice? Large Language Models and the False Promise of Creativity", "summary": "Work led by Tuhin Chakrabarty as an intern at Salesforce Research. Are LLMs capable of high-quality creative fictional writing, to the level of short-stories published in the New Yorker. We designed a methodology to evaluate story quality (through rigorous manual evaluation by expert writers), and found a very large gap between professionally-written and AI-generated stories. Neat Finding: at the time, LLMs were not capable of even judging which stories were better than others, and tended to favor more bland AI-like writing.", "additional_links": {"code": "https://github.com/salesforce/creativity_eval", "data (hf)": "https://huggingface.co/datasets/Salesforce/ttcw_creativity_eval", "video": "https://dl.acm.org/doi/10.1145/3613904.3642731"}},
        {"id": "ai_writing_idiosyncracies", "title": "Writing Idiosyncracies", "venue": "CHI2025", "url": "https://arxiv.org/abs/2409.14509", "is_left_child": 1, "parent": "art_or_artifice", "coauthors": ["Tuhin Chakrabarty", "Chien-Sheng Wu"], "full_title": "Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving Human-AI Alignment in the Writing Process through Edits", "summary": "Work led by Tuhin at Salesforce Research. Following up on Art or Artifice. Lowering our expectation from a story (1000+ words) to a single paragraph (100-200 words). We find in a controlled experiment that LLMs still struggle to generate high-quality creative writing even in shorter form. Neat finding: when allowing an LLM to: (1) draft, (2) detect issues, (3) edit them through executable edits, then LLMs are capable of <b>improving</b> their writing!", "additional_links": {"code": "https://github.com/salesforce/creativity_eval/"}},
        {"id": "inksync", "title": "InkSync", "venue": "UIST2024", "url": "https://arxiv.org/abs/2309.15337", "indirect_connections": ["ai_writing_idiosyncracies"], "parent": "swipe", "coauthors": ["Jesse Vig", "Marti A. Hearst", "Caiming Xiong", "Chien-Sheng Wu"], "full_title": "Beyond the Chat: Executable and Verifiable Text-Editing with LLMs", "summary": "How do we imagine writing with an LLM should look like. We design the concept of 'executable edits' that an LLM-based system can propose, and design a framework to verify factual accuracy of these edits (Warn-Verify-Audit).", "additional_links": {"demo video": "https://www.youtube.com/watch?v=q7lf5CIMyvE", "live demo": "https://inksync.salesforceresearch.ai/", "code": "https://github.com/SalesforceAIResearch/inksync", "recorded presentation": "https://www.youtube.com/watch?v=3RMo1nWIqCY"}},

        {"id": "writing_quality_reward_models", "title": "Writing Quality Reward Models", "venue": "arXiv", "url": "https://arxiv.org/abs/2504.07532", "is_left_child": 1, "parent": "ai_writing_idiosyncracies", "coauthors": ["Tuhin Chakrabarty", "Chien-Sheng Wu"], "full_title": "AI-Slop to AI-Polish? Aligning Language Models through Edit-Based Writing Rewards and Test-time Computation", "summary": "Work co-led with Tuhin Chakrabarty continuing our great CHI2025. In this work, we build out methods to evaluate *writing quality* in for fiction and non-fiction writing tasks. We release a model (WQRM) we believe is best-in-class at measuring writing quality, as confirmed by our benchmark results.", "additional_links": {"code": "https://github.com/salesforce/creativity_eval/", "model": "huggingface.co/models?search=wqrm", "data": "https://github.com/salesforce/creativity_eval/tree/main/WritingRewards/WQ-benchmark-data"}},

        {"id": "summaryloop", "title": "Summary Loop", "venue": "ACL2020", "url": "https://arxiv.org/abs/2105.05361", "root_node": 1, "root_name": "Summarization\n2019-now", "root_color": "#FFE699", "coauthors": ["Andrew Hsi", "John Canny", "Marti A. Hearst"], "full_title": "The Summary Loop: Learning to Write Abstractive Summaries Without Examples", "summary": "My first foray into summarization! We designed an entirely unsupervised method for summarization that relied on RL optimization (before it was cool) to train a 'language model' (GPT2) to jointly optimize information coverage & fluency. Neat Idea: the most complex element to define was the Coverage scoring method, check it out in the paper.", "indirect_connections": ["keepitsimple"], "additional_links": {"video": "https://slideslive.com/38929183/summary-loop-unsupervised-abstractive-summarization", "code": "https://github.com/CannyLab/summary_loop", "models": "https://huggingface.co/philippelaban/summary_loop46"}},
        {"id": "summac", "title": "SummaC", "venue": "TACL2021", "url": "https://arxiv.org/abs/2111.09525", "parent": "summaryloop", "coauthors": ["Tobias Schnabel", "Paul N. Bennett", "Marti A. Hearst"], "full_title": "SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization", "summary": "First adventures with factuality/faithfulness/consistency in text generation & summarization. At the time, most of the work had shown NLI methods did not work reliably to detect factual errors in generated text, and relied instead on more complex QG/QA pipelines. The work shows that more modern NLI models, when used at the right granularity, are competitive and much faster to run. We released the two models & the benchmark we created (SummaC).", "additional_links": {"video": "https://aclanthology.org/2022.tacl-1.10.mp4", "code/data": "https://github.com/tingofurro/summac"}},


        {"id": "summedits", "title": "SummEdits", "venue": "EMNLP2023", "url": "https://arxiv.org/abs/2305.14540", "parent": "summac", "coauthors": ["Wojciech Kryściński", "Divyansh Agarwal", "Alexander R. Fabbri", "Caiming Xiong", "Shafiq Joty", "Chien-Sheng Wu"], "full_title": "LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond", "summary": "First work leveraging LLMs (GPT-3.5-turbo)! Can we use an LLM as part of a benchmark creation process to lower the cost of data acquisition while maintaining quality. Neat Finding: we create a dataset for summary factual inconsistency detection that costs 20x less per sample with very high IAA. Most LLMs at the time struggled to beat near-random performance on SummEdits.", "additional_links": {"video": "https://aclanthology.org/2023.emnlp-main.600.mp4", "data (hf)": "https://huggingface.co/datasets/Salesforce/summedits", "code": "https://github.com/salesforce/factualNLG"}},
        {"id": "summary_of_a_haystack", "title": "Summary of a Haystack", "is_left_child": 1, "venue": "EMNLP2024", "url": "https://arxiv.org/abs/2407.01370", "parent": "summedits", "coauthors": ["Alexander R. Fabbri", "Caiming Xiong", "Chien-Sheng Wu"], "full_title": "Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems", "summary": "How good are LLMs or RAG systems at dealing with long-context (~100k tokens) and precisely summarizing and citing back to relevant documents. Alex Fabbri & I very carefully synthesized Haystacks of documents to explore the subject. Neat Finding: in 2024, RAG vs. long-context LLMs is not a winner takes all (yet). RAGs are better when citation/attribution is important, whereas long-context single-step is more competitive when information (without citation) is desired.", "additional_links": {"data (hf)": "https://huggingface.co/datasets/Salesforce/summary-of-a-haystack", "code": "https://github.com/salesforce/summary-of-a-haystack"}},
        {"id": "answer_engine_eval", "title": "Answer Engine Eval.", "venue": "FAccT 2025", "url": "https://arxiv.org/abs/2410.22349", "parent": "summary_of_a_haystack", "coauthors": ["Pranav Narayanan Venkit", "Yilun Zhou", "Yixin Mao", "Chien-Sheng Wu"], "full_title": "Search Engines in an AI Era: The False Promise of Factual and Verifiable Source-Cited Responses", "summary": "Work led by Pranav Venkit as an intern at Salesforce Research. Explored whether 'answer engines' (generative search engines, which are simply RAG-based summarization systems) capbale of producing accurate and attributed answers to technical user queries. Neat Finding: the qualitative study led to a quantitative framework with ~8 metrics, most of which current answer engines struggle on.", "additional_links": {"code": "https://github.com/SalesforceAIResearch/answer-engine-eval"}},


        {"id": "aggrefact", "title": "AggreFact", "venue": "ACL2023", "url": "https://arxiv.org/abs/2205.12854", "parent": "summac", "coauthors": ["Liyan Tang", "Tanya Goyal", "Alexander R. Fabbri", "Jiacheng Xu", "Semih Yavuz", "Wojciech Kryściński", "Justin F. Rousseau", "Greg Durrett"], "full_title": "Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors", "summary": "Work led by Liyan Tang on creating a larger-scale benchmark for factuality in summarization (AggreFact) to better understand error types that occur across model generations. Neat Finding: the distribution of factual error types shifts with different generations of models. As generative models get better, the kinds of factual errors they make become more subtle... and more difficult to catch. (oh no!)", "additional_links": {"video": "https://aclanthology.org/2023.acl-long.650.mp4", "data": "https://github.com/Liyan06/AggreFact"}},

        {"id": "minicheck", "title": "MiniCheck", "venue": "EMNLP2024", "url": "https://arxiv.org/abs/2404.10774", "parent": "aggrefact", "indirect_connections": ["summedits", "answer_engine_eval"], "coauthors": ["Liyan Tang", "Greg Durrett"], "full_title": "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents", "summary": "Work led by Liyan Tang. Very clever data synthesis process to create challenging (positive/negative) samples for factual inconsistency detection. When training a model on the synthetic data, we obtain a factual inconsistency checker as good as the top LLMs (Claude / GPT) but 300x cheaper to run!", "additional_links": {"code": "https://github.com/Liyan06/MiniCheck", "leaderboard": "https://llm-aggrefact.github.io/", "model (hf)": "https://huggingface.co/bespokelabs/Bespoke-MiniCheck-7B", "data (hf)": "https://huggingface.co/datasets/lytang/LLM-AggreFact"}},

        {"id": "newslens", "title": "NewsLens", "venue": "ACL2017 Workshop", "url": "https://aclanthology.org/W17-2701.pdf", "root_node": 1, "root_name": "Reading\n2016-2023", "root_color": "#FA9189", "coauthors": ["Marti A. Hearst"], "full_title": "newsLens: building and visualizing long-ranging news stories", "summary": "My first foray into news reading interfaces, presented at the News Workshop of ACL 2017. The work presents how a large-scale stream of news articles can be organized into evolving news timelines, how to name and visualize them."},
        {"id": "news_chatbot", "title": "News Chatbot", "venue": "ACL2020", "url": "https://arxiv.org/abs/2105.05392", "parent": "newslens", "coauthors": ["John Canny", "Marti A. Hearst"], "full_title": "What's The Latest? A Question-driven News Chatbot", "summary": "For the NewsLens stories, what would it look like to 'chat' with a system about an evolving news story's that can have 1000+ articles (pre-ChatGPT !!). Neat Finding: if you recommend questions to users, they can have fairly long conversation, reading through more than an average article's length of content.", "additional_links": {"video": "https://slideslive.com/38928615/whats-the-latest-a-questiondriven-news-chatbot"}},
        {"id": "newspod", "title": "Podcasts", "venue": "IUI2022", "url": "https://arxiv.org/abs/2202.07146", "parent": "news_chatbot", "coauthors": ["Elicia Ye", "Srujay Korlakunta", "John Canny", "Marti A. Hearst"], "full_title": "NewsPod: Automatic and Interactive News Podcasts", "summary": "Taking Newslens and its chat to the next level: by exploring whether stoires can be turned into conversational (multi-voice) and interactive (user can speak) podcasts. Neat Finding: using multiple voices when synthesizing speech lowers user fatigue, and adding a Q&A format reduces monotonicity. Users are sometimes willing to jump in and ask their own questions.", "additional_links": {"live_demo": "https://newspod.github.io/", "Interview (Apple Podcast)": "https://podcasts.apple.com/ca/podcast/like-your-new-best-friend-an-ai-chatbot/id1639175294?i=1000575694297"}},
        {"id": "news_headline_grouping", "title": "Headline Grouping", "venue": "NAACL2021", "url": "https://arxiv.org/abs/2105.05391", "parent": "news_chatbot", "coauthors": ["Marti A. Hearst"], "full_title": "News Headline Grouping as a Challenging NLU Task", "summary": "Focused work on a challenging NLP task related to news headline writing. Can we automatically detect when two headlines relate to the same real-world event? It happens to be challenging because of the complex process involved in crafting news headlines.", "additional_links": {"code": "https://github.com/tingofurro/headline_grouping", "data (HF)": "https://huggingface.co/philippelaban/headline_grouping", "video": "https://aclanthology.org/2021.naacl-main.255.mp4"}},
        {"id": "discord_questions", "title": "Discord Questions", "venue": "EMNLP2022", "url": "https://arxiv.org/abs/2211.05007", "parent": "news_headline_grouping", "coauthors": ["Chien-Sheng Wu", "Lidiya Murakhovs'ka", "Xiang 'Anthony' Chen", "Caiming Xiong"], "full_title": "Discord Questions: A Computational Approach To Diversity Analysis in News Coverage", "summary": "Given a set of news articles (and/or documents) that cover a common topic (news event), can we find key questions that surface when the sources agree, or disagree. Can these be used to surface the diversity in coverage that exists in the corpus? Neat Finding: even pre-ChatGPT, this was possible: over-generate 100+ questions, and filter out to the few that fit strict criteria.", "additional_links": {"video": "https://aclanthology.org/2022.findings-emnlp.380.mp4", "code": "https://github.com/salesforce/discord_questions", "data": "https://huggingface.co/Salesforce/qa_consolidation", "models": "https://huggingface.co/Salesforce/discord_qg"}},
        {"id": "assembly", "title": "Assembly", "venue": "CHI2023", "url": "https://arxiv.org/abs/2302.08997", "parent": "discord_questions", "coauthors": ["Chien-Sheng Wu", "Lidiya Murakhovs'ka", "Xiang 'Anthony' Chen", "Caiming Xiong"], "full_title": "Designing and Evaluating Interfaces that Highlight News Coverage Diversity Using Discord Questions", "summary": "Once we have Discord Questions, how do we use them in practice in news reading interfaces, both for journalism professionals, and everyday newsreaders (the 'Assembly' interfaces). Neat Finding: we showed in a study with 100+ participants that the annotated article interface leads to better access to coverage diversity, while not being more complicated to use (success!).", "additional_links": {"video": "https://www.youtube.com/watch?v=s2mBv3xD7Lg"}},
        {"id": "diverse_summ", "title": "DiverseSumm", "venue": "NAACL2024", "url": "https://arxiv.org/abs/2309.09369", "indirect_connections": ["summary_of_a_haystack"], "parent": "assembly", "coauthors": ["Kung-Hsiang Huang", "Alexander R. Fabbri", "Prafulla Kumar Choubey", "Caiming Xiong", "Chien-Sheng Wu"], "full_title": "Embrace Divergence for Richer Insights: A Multi-document Summarization Benchmark and a Case Study on Summarizing Diverse Information from News Articles", "summary": "Follow-up of Discord Questions & Assembly. Once we've found a topic of discord within a corpus of documents, how good are LLMs at describing this diversity when they summarize the information. Neat finding: LLMs are not so good at nuanced summarization, and tend to focus on information either at the top/bottom of their context window (arbitrary), or on predominantly represent opinion. Work led by Steeve Huang when he was an intern at Salesforce Research!", "additional_links": {"code/data": "https://github.com/salesforce/DiverseSumm"}}
    ]

        build_garden(papers);
    </script>

</body>
</html>
